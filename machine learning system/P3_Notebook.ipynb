{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Part A"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-01-19T10:50:15.370833Z","iopub.status.busy":"2022-01-19T10:50:15.370516Z","iopub.status.idle":"2022-01-19T10:50:15.376813Z","shell.execute_reply":"2022-01-19T10:50:15.375873Z","shell.execute_reply.started":"2022-01-19T10:50:15.370799Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-01-19T10:50:15.558940Z","iopub.status.busy":"2022-01-19T10:50:15.558340Z","iopub.status.idle":"2022-01-19T10:50:15.569038Z","shell.execute_reply":"2022-01-19T10:50:15.568080Z","shell.execute_reply.started":"2022-01-19T10:50:15.558889Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd #data pre-processing\n","import matplotlib #data visualization \n","import matplotlib.pyplot as plt #data visualization \n","import seaborn as sns #data visualization \n","import missingno as msno #Missing value interpretation\n","from IPython.display import display\n","\n","#import rossvalidation and train_test_split class\n","from sklearn.model_selection import KFold,RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n","from sklearn.model_selection import train_test_split\n","\n","# different scaling strategy classes \n","from sklearn.preprocessing import StandardScaler, MinMaxScaler,LabelEncoder\n","\n","#Pipeline to assemble several steps that can be cross-validated together while setting different parameters\n","from sklearn.pipeline import Pipeline\n","\n","#Set of different regression algorithms for the analysis\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.svm import SVR\n","\n","# different imputation strategies\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n","from collections import Counter\n","\n","#evaluation metrics\n","from sklearn.metrics import  mean_squared_error,mean_absolute_error\n","from sklearn.metrics import  r2_score\n","\n","from math import sqrt"]},{"cell_type":"markdown","metadata":{},"source":["## Predictor class which compares different regression models and selects best model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-01-19T10:54:02.768722Z","iopub.status.busy":"2022-01-19T10:54:02.768387Z","iopub.status.idle":"2022-01-19T10:54:02.802459Z","shell.execute_reply":"2022-01-19T10:54:02.801161Z","shell.execute_reply.started":"2022-01-19T10:54:02.768667Z"},"trusted":true},"outputs":[],"source":["class predictor:\n","    data = pd.DataFrame()\n","    test_data = pd.DataFrame()\n","    imp = ''\n","    scalingStrategy = ''\n","    pred = ''\n","    \n","    def __init__(self,data, imp='missing', strategy = 'standard'):\n","        #receives data and makes copy to avoid working on original data\n","        self.data = data.copy(deep=True)\n","        self.imp = imp\n","        self.scalingStrategy = strategy\n","        \n","        \n","    def visualizeResults(self,best_model): #Visualizes the regressors results for comparison\n","        clfs      = []\n","        result    = pd.DataFrame(best_model.cv_results_)\n","        #sort models based on rank after cross validation\n","        result    = result.sort_values('rank_test_score')\n","                \n","        m = [['LinearRegression','lr'],['XGBRegressor','xgb'],['GradientBoostingRegressor','gbr'],\n","            ['AdaBoostRegressor','abr'],['DecisionTreeRegressor','dtr'],['RandomForestRegressor','rfr']\n","            ,['SVR','svr']]\n","        \n","        for i in result['param_regressor']:\n","            for j in range(len(m)):\n","                if m[j][0] == type(i).__name__:\n","                    clfs.append(m[j][1])\n","                    \n","                    \n","        print('\\n')\n","        #plot comparison line graph of different classification models\n","        data_plot = pd.DataFrame({\"Regressor\": clfs,\"Results\":result['mean_test_score']})\n","        sns.lineplot(x = \"Regressor\", y = \"Results\", data=data_plot)\n","        plt.title('Regressors comparative analysis')\n","        plt.show()\n","        \n","        \n","    def immputation(self, data): #immpute and encode dataframe using different stratigies \n","        \n","        #Replace categorical data with ordinal values to retain relationship\n","        transform = {\"F20\": {\"Very low\":0, \"Low\":1, \"Medium\":2, \"High\":3, \"Very high\":4}}\n","        data.replace(transform, inplace=True)\n","        #Perform one hot encoding to transform categorical data into numerical\n","        data = pd.get_dummies(data, columns= ['F27'])\n","        #Re-arranges the dataset so Target is at the end\n","        data = data[['F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12','F13','F14','F15','F16',\n","                   'F17','F18','F19','F20','F21','F22','F23','F24','F25','F26','F28','F29','F30'\n","                   ,'F31','F32','F33','F34','F35','F36','F27_Europe','F27_Rest','F27_UK','F27_USA','Target']]\n","        \n","        # feature column\n","        X = data.iloc[:, 0:39] \n","        #Isolates the Target column from the dataset\n","        Y = data.iloc[:, [39]]    \n","        \n","        #chaining function calls featureScaling \n","        return self.featureScaling(X,Y)\n","    \n","    def featureScaling(self, feature, target): #Normalise data using specified strategy\n","        feature_temp = ''\n","        if self.scalingStrategy == 'minmax': #Transform features by scaling each feature to a given range.\n","            scaler = MinMaxScaler().fit(feature)\n","            MinMaxScaler()\n","            feature_temp = scaler.transform(feature)\n","        elif self.scalingStrategy == 'standard': #Standardize features by removing the mean and scaling to unit variance.      \n","            scaler = StandardScaler().fit(feature)\n","            StandardScaler()\n","            feature_temp = scaler.transform(feature)\n","        #Target encoding\n","        target = LabelEncoder().fit_transform(target)\n","        return (feature_temp, target) \n","    \n","#     def visualizeResult(self, result, best_model):\n","#         pass\n","\n","    def predict(self,best_model):  #prediction using test data \n","        #Read test dataset from csv\n","        self.test_data      = pd.read_csv('CE802_P3_Test.csv')       \n","        temp      = self.test_data.copy(deep=True) \n","        #perform imputation and feature scaling on the test set\n","        X_test    = self.immputation(temp)[0]\n","        #predict the target value for the given test feature\n","        y_pred    = best_model.predict(X_test)\n","        #store predicted values\n","        self.pred = y_pred\n","\n","                \n","        \n","    def modelFinder(self, clfs):#compares and finds the best model\n","        \n","        #Performs immputation and feature scaling on the training set\n","        immputed = self.immputation(self.data)\n","        feature, target = immputed[0], immputed[1]\n","        X_train,X_test,y_train,y_test=train_test_split(feature,target,test_size=0.2,random_state=0)\n","        print('X_train : ',X_train.shape ,'y_train : ',y_train.shape)\n","    \n","        params = {\n","                    'lr':{\"regressor\": [LinearRegression()], },\n","                    'svr':{\"regressor\": [SVR(C=1.0, epsilon=0.2)], },\n","                    'dtr':{\"regressor\": [DecisionTreeRegressor()], \n","                          \"regressor__max_depth\" : [3,5,7,9,10,15,20,25],\n","                           \"regressor__min_samples_leaf\": [1,2,3,4,5,6,7,8,9,10] ,\n","                          },\n","                    'rfr':{\"regressor\": [RandomForestRegressor()],\n","                          \"regressor__n_estimators\": [1, 2, 4, 8, 16, 32, 64, 100, 200],\n","                          \"regressor__bootstrap\" :[True, False],\n","                           \"regressor__max_depth\" : [3,5,7,9,10,15,20,25],\n","                           \"regressor__min_samples_leaf\" :[1,2,3,4,5,6,7,8,9,10],\n","                           \"regressor__n_estimators\" :[1, 2, 4, 8, 16, 32, 64, 100, 200]\n","                          \n","                          },\n","                           'gbr':{\"regressor\": [GradientBoostingRegressor()], \n","                           \"regressor__learning_rate\":[1, 0.5, 0.25, 0.1, 0.05, 0.01],\n","                           \"regressor__n_estimators\": [1, 2, 4, 8, 16, 32, 64, 100, 200],\n","                           \"regressor__max_depth\":[3,5,7,9,10,15,20,25],\n","                          },\n","                    'abr':{\"regressor\": [AdaBoostRegressor()],\n","                          \"regressor__n_estimators\": [1, 2, 4, 8, 16, 32, 50, 64, 100, 200],\n","                           \"regressor__learning_rate\":[1, 0.5, 0.25, 0.1, 0.05, 0.01],\n","                           \n","                          },\n","                }  \n","        pipe = Pipeline([(\"regressor\", RandomForestRegressor())])\n","        # Create dictionary with candidate learning algorithms and their hyperparameters\n","        grid_param = [params[i] for i in clfs ]   \n","        # create a gridsearch of the pipeline, the fit the best model\n","        gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n","        best_model = gridsearch.fit(X_train,y_train)\n","        self.visualizeResults(best_model)\n","        #prediction using best model on test set\n","        pred = best_model.predict(X_test)\n","        \n","        print('\\n-------------------------------------------------------------------------------------------------------------\\n')\n","        #model evaluation metrics\n","        print(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))\n","        print('Mean Squared Error               : %.2f'% mean_squared_error(y_test, pred))\n","        print('Coefficient of Determination     : %.2f'% r2_score(y_test, pred))\n","        #calls prediction function with best model as the argyment\n","        self.predict(best_model)\n","\n","\n","\n","\n","   \n","      \n"]},{"cell_type":"markdown","metadata":{},"source":["## Main class of the machine learning system with fuction for each functionality of the learning procedure"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-01-19T10:54:03.151263Z","iopub.status.busy":"2022-01-19T10:54:03.150959Z","iopub.status.idle":"2022-01-19T10:54:03.171063Z","shell.execute_reply":"2022-01-19T10:54:03.170195Z","shell.execute_reply.started":"2022-01-19T10:54:03.151229Z"},"trusted":true},"outputs":[],"source":["class Mlsystem: #Mlsytem main class of the ananlysis\n","    df = ''\n","    df_test = pd.DataFrame() \n","    df_org = ''\n","    predicted = ''\n","    \n","    \n","    def __init__(self):\n","        #Reads both train and test set for the experiment\n","        self.df      = pd.read_csv('CE802_P3_Data.csv')\n","        self.df_test = pd.read_csv('CE802_P3_Test.csv')\n","        #makes copy to avoid making changes to original dataset\n","        self.df_org  = self.df.copy(deep=True) \n","    \n","    def space(self):\n","        print('\\n-------------------------------------------------------------------------------------------------------------\\n')\n","\n","        \n","    def featureEngineering(self): #Feature engineering procedures \n","        \n","        display(self.df.head())\n","        self.space()\n","       \n","        print('Columns Data type and Null Counter \\n')\n","        print(self.df.info()) # column wise information of the DataFrame\n","        self.space()\n","        \n","        print('Rows * columns of training set : ',self.df.shape) # shape of the dataframe\n","        self.space()\n","        \n","        print('Description of given data \\n')\n","        t = self.df.describe().T\n","        display(t)\n","        self.space()\n","        \n","        print('Missing value indicator : ', self.df.isna().any().any()) # missing value detection        \n","        self.space()\n","        \n","        \n","        print('Null value indicator    : ', self.df.isnull().values.any()) #Checking presence of empty values       \n","        self.space()\n","        \n","        #Use bar char to find frequeny of the missing value\n","        print('Missing value identification using bar chart \\n')\n","        msno.bar(self.df)\n","        plt.figure()\n","        plt.show()\n","        self.space()  \n","        \n","        #barchart representation of each feature for interpretation  \n","        print('Check Data skewness using Bar chart \\n')\n","        self.df.hist(bins=30, figsize=(20, 15))\n","        plt.figure()\n","        plt.show()   \n","        self.space()    \n","    \n","        \n","    def featureSelection(self): #To carry out feature selection procedures\n","        start = \"\\033[1m\"\n","        end = \"\\033[0;0m\"        \n","        # calculate correlation matrix\n","        print(start+'Correlation matrix heatmap'+end+'\\n'.center(200))\n","        corr = self.df.corr()# plot the heatmap\n","        fig, ax = plt.subplots(figsize=(25,25))         # Sample figsize in inches\n","        sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))\n","        plt.figure()\n","        plt.show()      \n","#       Detect outliers using boxplot\n","        self.space()  \n","        fig, ax = plt.subplots(figsize=(15,5)) \n","        print(start+'Outlier detection using Box plot'+end+'\\n'.center(110))\n","        self.df.boxplot()\n","        plt.show()\n","    \n","    def modelBuilding(self, models, imp='missing', scalingStrategy='standard'):\n","        #Creates predictor instance to compare and find best model\n","        pred = predictor(self.df,imp,scalingStrategy)\n","        #compare and find best model and predict results\n","        pred.modelFinder(models)\n","        #gets predicted values from the predictor and store it on instance variable\n","        self.predicted = pred.pred\n"]},{"cell_type":"markdown","metadata":{},"source":["## Object oriented procedure for the learning system"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-01-19T10:54:03.773111Z","iopub.status.busy":"2022-01-19T10:54:03.772846Z","iopub.status.idle":"2022-01-19T10:54:27.316752Z","shell.execute_reply":"2022-01-19T10:54:27.315489Z","shell.execute_reply.started":"2022-01-19T10:54:03.773084Z"},"trusted":true},"outputs":[],"source":["#Choose from List of models for the experiment\n","models = [\n","    'lr', 'gbr',\"abr\",\n","    'dtr','rfr','svr'\n","]\n","#Choose between different immputation methods\n","impStrategies = ['missing','mean','iterative','knn']\n","#Choose from different feature scaling methods\n","scalingStrategies = ['standard', 'minmax']\n","#Creates instance of Mlsystem class\n","ml = Mlsystem()\n","#Feature Engineering procedures\n","ml.featureEngineering()\n","#Feature selection procedures\n","ml.featureSelection()\n","#creates instance of predict class to compare and find best regressor for prediction then \n","# uses the best model to predict and store results on the instance variable self.predicted\n","ml.modelBuilding(models,imp=impStrategies[0], scalingStrategy=scalingStrategies[0] )\n","# joblib.dump(gs.best_estimator_, 'filename.pkl')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:05:18.465457Z","iopub.status.idle":"2022-01-19T08:05:18.465822Z","shell.execute_reply":"2022-01-19T08:05:18.465648Z","shell.execute_reply.started":"2022-01-19T08:05:18.465627Z"},"trusted":true},"outputs":[],"source":["ml.predicted"]},{"cell_type":"markdown","metadata":{},"source":["## Part B"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# HERE YOU WILL USE THIS TEMPLATE TO SAVE THE PREDICTIONS ON THE TEST SET\n","\n","# Load the test data\n","# test_df = pd.read_csv('../input/mlassignmentpart3/CE802_P3_Test.csv')\n","\n","# Make sure you work on a copy\n","test_data = test_df.iloc[:,:-1].copy()\n","\n","predicted = ml.predicted # CHANGE HERE -- use your previously trained predictor and apply it to test_data\n","                # (test_data can be modified if needed but make sure you don't change the order of the rows)...\n","\n","# Replace the last (empty) column with your prediction\n","test_df.iloc[:,-1] = predicted\n","test_df.head(30)\n","\n","# Save to the destination file\n","test_df.to_csv('CE802_P3_Test_Predictions.csv', index=False, float_format='%.8g')\n","\n","# IMPORTANT!! Make sure only the last column has changed\n","assert pd.read_csv('CE802_P3_Test.csv').iloc[:,:-1].equals(pd.read_csv('CE802_P3_Test_Predictions.csv').iloc[:,:-1])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
